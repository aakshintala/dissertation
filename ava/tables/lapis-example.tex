% -*- fill-column: 85; -*-
%!TEX root = ../main.tex

\begin{figure}
%@@cuMemcpyHtoDAsync(CUdeviceptr dst, void *src,|\label{line:cuMemcpyHtoDAsync}|
%           size_t size, CUstream stream)@@ { 
%  async; success(CUDA_SUCCESS);
%  argument(src) { in;|\label{line:src-in}| buffer(size); lifetime_manual; }
%  register_buf(async_HtoD, stream, src, size); }
\begin{lstlisting}[language=C,style=nwspecc,columns=flexible,belowskip=-0.5em,aboveskip=-0.5em,mathescape,basicstyle={\scriptsize\ttfamily}]
continuous_rc device_memory;
instantaneous_rc kernel_invocations;|\label{line:declare_rc}|
policy("policy_kern.c");|\label{line:scheduler_code}|
struct fn_arg_info {
  // CUfunction type information, filled by other LAPIS code
  int fn_argc;
  char fn_arg_is_handle[64];
  size_t fn_arg_size[64];
};
declare_metadata(struct fn_arg_info);
buf_registry async_DtoH;
type(CUdeviceptr) { handle; }|\label{line:cudeviceptr-handle}|
@@cuMemAlloc(CUdeviceptr *pp, size_t size)@@ { 
  allocates_rc(device_memory, size);|\label{line:allocates_rc}|
  argument(pp) { out; element { obj_record; allocate; } } }
@@cuMemcpyDtoHAsync(void* dst, CUdeviceptr src,|\label{line:cuMemcpyDtoHAsync}| 
                    size_t size, CUstream stream)@@ {
  async; success(CUDA_SUCCESS);|\label{line:success}|
  argument(dst) { no_copy;|\label{line:dst-nocopy}| buffer(size); lifetime_manual; }
  register_buf(async_DtoH, stream, dst, size); }
@@cuLaunchKernel(CUfunction f,
    uint gridDimX, uint gridDimY, uint gridDimZ,
    uint blockDimX, uint blockDimY, uint blockDimZ,
    uint sharedMemBytes, CUstream hStream,
    void **kernelParams, void **extra)@@ {
  async; consumes_rc(kernel_invocation, 1);|\label{line:consume_rc}|
  argument(kernelParams) {
    in; buffer(metadata(f)->fn_argc);
    element {
      if (metadata(f)->fn_arg_is_handle[index]) {
        type_cast(CUdeviceptr*); buffer(1);
      } else {
        type_cast(void*); buffer(metadata(f)->fn_arg_size[index]);
      } } }
  argument(extra) { in; ... } }
@@cuStreamSynchronize(CUstream stream)@@ {
  contextual_argument void** bufs =|\label{line:sync-bufs-1}| get_bufs(async_DtoH, stream);|\label{line:sync-bufs-2}|
  argument(bufs) {
    in; buffer(get_n_bufs(async_DtoH, stream));
    element { 
      buffer(get_buf_size(async_DtoH, stream, index));
      out; deallocate; } } }|\label{line:dst-buf-out}|
\end{lstlisting}
% no_copy; buffer(get_async_free_buf_size(stream, index));
\caption{
An example \speclang description for the CUDA driver API.
Code elements in {\lapiskeywordstyle bold blue} are \speclang keywords, elements in {\lapisstdlibstyle italic green} are runtime library calls, 
elements in {\lapisprototypestyle gray} are function prototypes incorporated by \compiler from the original CUDA header file,
and the remaining code is programmer-provided \speclang.
The variable \spec|index| is a \speclang builtin which provides the index of the current element of a buffer.
The specification of the argument \spec|extra| to \spec|cuLaunchKernel| is complex due to alignment and padding, and is elided from this example for clarity. 
%The specification of \spec|extra| is overall very similar to the specification of \spec|kernelParams|.
The file \spec|policy_kern.c| is shown in Figure~\ref{fig:scheduler_example}.
}
\label{fig:lapis-values-example}
\label{fig:spec_example}
\vspace*{-0.5em}
\end{figure}
