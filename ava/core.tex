% -*- fill-column: 85; -*-
%!TEX root = ../dissertation.tex

\graphicspath{{images/}}

\subsection{Communication Transport}
\label{s:design_transport}

\AvA relies on an abstract communication channel that defines how
calls, and their associated data buffers, and results are sent, validated, and received.
%The channel interface provides primitives to send/receive commands.
% to marshal/unmarshal function arguments and  AMP: Our channel does not provide marshalling other than buffer attachment, so I don't think it's important and could confuse people as marshalling can imply things like encoding strings or numbers.
The channel provides an interposition point to track resources and invoke policies from the \Lapis specification.
Using an abstract interface allows hypervisor developers to choose the best available communication transport
(e.g., shared memory FIFOs vs RDMA).
While the channel explicitly requires that all communication between the guest
and the \worker must take place through the router, no assumptions are made
about the actual location of components, which may be
disaggregated.


% \subsection{Callbacks}
%\label{s:callback}
\AvA communication is bidirectional: it must support function callbacks from the \worker to the guest library, because
callbacks are fundamental in many frameworks, e.g., TensorFlow,
and must be run in the guest VM. % (instead of the \worker) to
%protect host domain from malicious code.\cjr{I think it would also be incorrect to run them anywhere else.}
In \AvA, the transport handles two types of payloads: \emph{commands} which contain opaque arguments and metadata for calls (e.g., thread ID and function ID) and \emph{data} which contains buffers referenced from the arguments (e.g., bulk data).

\subsection{Sharing and Protection}
\label{s:protection}

\AvA re-purposes process-level isolation mechanisms (e.g. memory protection)
provided by the accelerator silo when it is available to simplify supporting cross-guest
isolation. We anticipate that emerging accelerators will support process-level isolation, as all GPUs do today.
% We reiterate that lack of hardware virtualization support is not the obstacle for accelerator virtualization,
% but stack structure is: if and when all accelerators support process-level virtualization in hardware,
% \AvA will still be necessary because vendor stacks do not expose the interfaces required to take advantage
% of that support.
%~\cjr{This last sentence is important, but too long.}
%~\cjr{But, we're going to keep it.}
For accelerators that do not natively support process-level isolation,
\AvA can still share device, relying on semantic information from additional \Lapis descriptors
to generate code that supports coarse-grain time-sharing, leveraging the same state capture techniques we use for VM migration (\S\ref{s:migration}).
% A descriptor on functions that create and destroy connections to hardware allows
% the \CAvA to insert additional logic in the device open/close calls to
% transparently spin until the device becomes available.
This solution admits no concurrency between tenants, but enables protected
sharing for devices which cannot otherwise be shared.

\subsection{Scheduling and Resource Allocation}
\label{s:rate_limit}
\label{s:api_throttling}

\AvA can enforce policies (e.g., rate limiting) on shared resources,
e.g., device execution time, by tracking resource consumption and invoking
policy callbacks that change how API calls from
guests (\S\ref{sub:scheduling}) are scheduled.
The developer provides policy callbacks in the \Lapis specification, and uses descriptors to identify how resources are consumed.
% ~\cjr{I assume this is a callback or something? The spec can't provide an approximation, but it can provide a way to get it, right?} of
%of the shared resource.
When such a descriptor is unavailable, \AvA falls back to coarse-grained
estimation of resource utilization, for example, using wall-clock time to approximate device execution time.
%We expect even such a rough approximation to be sufficient for useful policy enforcement.
% \hyu{We should say we can do better than wall-clock approximation.}
% \AvA uses adaptive call rate limiting, based on proportional time-sharing
% and feedback control~\cite{scheduling_survey} (see \S~\ref{sub:scheduling}).

% The \AvA router schedules only API function calls, like previous API
% remoting systems. However, unlike previous systems, the router runs in the
% hypervisor, and can be integrated/federated with schedulers for other resources to
% improve locality and performance.

\subsection{Memory Management}

To support memory sharing on devices with onboard memory, \Lapis resource usage descriptors
enable generated code to track the device memory
allocated to each guest VM. %based on the resource usage description in \Lapis. In this scenario, the router would rely on the
%\worker to notify it of all allocation and deallocation of device memory.
Resource accounting code is auto-generated from semantic knowledge of
the device memory allocation APIs (such as, memory types and how to compute size
of buffer) provided by descriptors in the API specification.
%If a device memory allocation request would exceed the guest's quota,
%the \worker returns the appropriate Out-of-Memory (OOM) error for the allocation.
