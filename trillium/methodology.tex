% !TeX root = ../dissertation.tex
\section{Methodology}
\label{sec_method}

All experiments were run on a Dell Precision 3620 workstation with NVIDIA
Quadro~6000 GPU and Intel Xeon CPU E5-2643 (3.40GHz) CPU. We implemented or
ported all prototypes and benchmarks on Ubuntu~16.04 with Xen~4.8.2. VMs were
hardware-accelerated via Xen Hardware Virtual Machines (HVM) with 2~virtual
CPUs (pinned) and 4~GB memory.

Of the GPU hardware available to us, the NVIDIA Quadro~6000 GPU was the only
one that GPUvm, the full-virtual\-ization baseline ran on. GPUvm depends on
GDev~\cite{gdev} an open source CUDA runtime (released in 2012) implemented
using Nouveau~\cite{nouveau} GPU drivers, and the CUDA~4.2 compiler on Linux
Kernel~3.6.5. GDev has not been maintained since 2014, and the effort to
update it was too onerous. This restricted all of our evaluation to the Quadro
6000. Experiments to control for hardware versions are reported in
\S\ref{sec:control}.

\subsection{Benchmarks}
\XenSVGA depends on the TGSI back-end compiler that we implemented to leverage
the Clover OpenCL runtime in Mesa3D. \apigpu and \apicpu leverage the NVIDIA
and Intel OpenCL library respectively and support all of the Rodinia
benchmarks. GPUvm is built on the GDev CUDA runtime, and can correctly execute
at least the same 10 benchmarks that run on \XenSVGA. Care was taken to ensure
that the CUDA and OpenCL versions of the benchmarks use the same parameters,
datasets, memory barriers, sync points, etc. Experiments to control for the
programming framework are reported in \ref{sec:control}.


\newcommand{\RowColor}{\rowcolor{red!50} \cellcolor{white}}
\newcommand{\NewBncColor}{\cellcolor{green!25}}
\newcommand{\FailBncColor}{\cellcolor{gray!50}}

\begin{table*}[!ht]
  \centering
  \begin{tabular}{rlc}
    \toprule
    \textbf{Benchmark} & \textbf{Description} & \textbf{Type} \\
    \midrule
    backprop & Back propagation (pattern recognition) & R \\
    gaussian & 256x256 matrix Gaussian elimination & D \\
    lud & 256x256 matrix LU decomposition & M \\
    nn & $k$-nearest neighbors classification & D \\
    nw & Needleman-Wunsh (DNA-seq alignment) & M \\
    pathfinder & Search shortest paths through 2-D maps & R \\
    \bottomrule
  \end{tabular}
  \caption{Benchmarks used in our evaluation grouped into in three categories:
  workloads where the cost of interpostion \textbf{D}ominates, workloads with \textbf{M}oderate amounts of events that must be interposed, and workloads that \textbf{R}arely exhibit interposition events.}
  \label{tb_bench}
\end{table*}

The 10 Rodinia benchmarks that our TGSI compiler could compile were
categorized based on frequency of interposition: Interposition-\textbf{D}
ominant workloads run kernels hundreds or thousands of times requiring
frequent interposition to set arguments, etc. Interposition-\textbf{R}are
workloads run a small number of long-running kernels, requiring very little
interposition. \textbf{M}oderate-interposition workloads lie somewhere in
between the other two. Two benchmarks were selected from each category
to be used in the evaluation (the optimizations described in
\S~\ref{sec:optimizations} take significant manual effort).

\subsection{Control Experiments}
\label{sec:control}

Software and platform version dependencies necessitated that our experimental
environments vary slightly for the systems under evaluation---%
different front-end programming languages (CUDA vs. OpenCL), different runtime
implementations (GDev CUDA vs. NVIDIA CUDA), or different drivers (Nouveau vs.
NVIDIA). Resolving all of these differences would have taken monumental
effort, but control experiments showed that these variables had negligible
impact on our measurements.

\paragraphbe{OpenCL vs. CUDA} GPUvm relies on the GDev implementation of the
CUDA framework, while all the other designs rely on OpenCL. To assess the
impact of different front-end languages on performance, we measured execution
times for all benchmarks in both CUDA and OpenCL (Rodinia includes both
implementations) holding all other variables constant, and found that the
front-end language has near negligible impact, and the harmonic mean of
differences in kernel execution time across all benchmarks is less than 1\%;
the worst (maximal) case is 15\%. We also found negligible difference in
performance between kernels compiled using CUDA 8.0 and the CUDA 4.2 required
by GDev.

\paragraphbe{Hardware Generations.} The performance improvements over the
span of generations between the Quadro 6000 and modern cards is substantial.
To estimate the effect of this variable we ran all benchmarks on both Quadro
6000 and a more recent GPU, Quadro P6000. While overall execution times are
improved substantially, and the ratio of time spent on the host to time spent
on the GPU changes as a result, the relative speedups are uniform across all
benchmarks. This suggests that the trends that we observe on the Quadro 6000
still hold on newer hardware. We re-iterate that software dependencies of the
GPUvm baseline prevent us from using more recent hardware. Our evaluation is
performed on the newest (several generations older) GPU hardware that all our
systems can run on.

\paragraphbe{Code generated by open source compiler vs Nvidia compiler}
We manually inspected the SASS binaries produced by the Nvidia and the `Clover
+ Nouveau' frameworks to understand the performance differences. While an in
depth of analysis is beyond the scope of this dissertation, we make the
following observations:

\begin{itemize}[nosep, topsep=0em, leftmargin=1em,labelwidth=*,align=left]
\item Both of the binaries benefit from common optimizations such as loop
  unrolling, and constant propagation, courtesy of LLVM.
\item SASS code produced through the TGSI has substantially more convergence
  points (SYNC and SSY) instructions, which represent additional opportunity
  for control flow divergence. Table~\ref{tab:sassdiferences} presents the number of control flow instructions in the two binaries, as a proxy for diverging control flow.
\item NVIDIA-produced SASS produces very different instruction sequences in
  several cases, e.g. XMAD (16bit Multiply Add) vs FFMA in TGSI (32-bit
  Fused Multipy Add). Our conjecture, in keeping with our hypothesis, is
  that the NVIDIA compiler has better information about which instructions
  more efficent on a particular architecture. It may be possible to
  reproduce some of these optimizations in the TGSI to SASS transformation,
  but since production of the TGSI code cannot rely on knowledge of the
  architecture, some optimizations may be impossible.
\end{itemize}
\input{trillium/sassdifferencestable}